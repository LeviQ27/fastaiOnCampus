{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artigo 7 - Filtros Colaborativos aplicado ao dataset *Book-Crossing: User review ratings*\n\n## Objetivo\n\nO objetivo deste presente trabalho é criar um modelo de recomendação de livros usando o dataset *Book-Crossing: User review ratings* aplicando filtros colaborativos aprendido na lição 7 do *fast.ai*.\n\n## Autor\n\n- Levi de Oliveira Queiroz 170108341\n- GitHub: LeviQ27\n- Kaggle User: lqueiroz27\n- HuggingFace User: L27Queiroz\n\n## Referência\n\n- Notebook Kaggle Utilizado como referência para produzir o presente artigo: https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook#Deep-Learning-for-Collaborative-Filtering\n\n- Lição 07 *Collaborative filtering* do *fastai*: https://course.fast.ai/Lessons/lesson7.html\n\n- O Dataset *Book-Crossing: User review ratings* utilizado: https://www.kaggle.com/datasets/ruchi798/bookcrossing-dataset\n\n## Inferência\n\nAplicativo HuggingFace: https://huggingface.co/spaces/L27Queiroz/BookRecomendations\n\n## Desenvolvimento\n\nComecei importando os módulos necessários para lidar com questões de filtragem colaborativa e com dados tabulares, também coloquei, assim como o Jeremy, uma semente 42 para geração de números aleatórios:","metadata":{}},{"cell_type":"code","source":"from fastai.collab import *\nfrom fastai.tabular.all import *\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:30.741769Z","iopub.execute_input":"2023-07-04T00:02:30.742499Z","iopub.status.idle":"2023-07-04T00:02:33.756671Z","shell.execute_reply.started":"2023-07-04T00:02:30.742458Z","shell.execute_reply":"2023-07-04T00:02:33.755406Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Feito a importação, comecei a verificar o dado escolhido para este presente trabalho. No local do dado é dito que contém 278,858 usuários (anonimizado mas com informações demográficas) provendo 1,149,780 classificações (explicita ou implicita) de 271,379 livros. Assim, fiz a leitura do arquivo csv *BX-Book-Ratings.csv*:","metadata":{}},{"cell_type":"code","source":"path = Path('../input/bookcrossing-dataset')\nratings = pd.read_csv(path/'Book reviews/Book reviews/BX-Book-Ratings.csv', encoding='latin-1', delimiter=';', header=None, usecols=(0,1,2), names=('user_id','isbn','rating'), low_memory=False)\nratings = ratings.drop(0)\nratings = ratings.reset_index(drop=True)\nratings.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:33.758171Z","iopub.execute_input":"2023-07-04T00:02:33.758812Z","iopub.status.idle":"2023-07-04T00:02:35.430970Z","shell.execute_reply.started":"2023-07-04T00:02:33.758779Z","shell.execute_reply":"2023-07-04T00:02:35.429637Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  user_id        isbn rating\n0  276725  034545104X      0\n1  276726  0155061224      5\n2  276727  0446520802      0\n3  276729  052165615X      3\n4  276729  0521795028      6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>276726</td>\n      <td>0155061224</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>276727</td>\n      <td>0446520802</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276729</td>\n      <td>052165615X</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>276729</td>\n      <td>0521795028</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Uma observação sobre o que foi feito no código: \nQuando é feito a leituros do arquivo csv *BX-Book-Ratings.csv* pelo `pd.read_csv()` apresenta um erro de leitura *utf-8*, para resolver apliquei como parâmetro `encoding='latin-1'`, que simplismente altera a linguagem de codificação de *utf-8* para *latin-1*. Logo após rodar novamente tive o erro de divisão de colunas, que por padrão, o pandas entende que `,` é um separador de colunas, por isso passei como parâmetro `delimiter=';'` que simplesmente altera o padrão de entendimento de separador do pandas de `,` para `;`. Em seguida tirei os título das colunas usando o parâmetro `header=None`, porém percebi que ao fazer isso a linha *0* era colocada com os títulos das colunas, para resolver isso apliquei a função de remoção da linha *0* usando `drop()` e resetei o index das linhas usando a função `reset_index(drop=True)`, de modo que o index das linhas é resetado e os títulos foram eliminados. Sem os título e seguindo as instruções do Jeremy, separei as colunas *0*, *1* e *2* com `usecols` e inseri os nomes das colunas usando `names`. A utilização do parâmetro `low_memory=False` foi feito por uma sugestão no Kaggle ao rodar o código sem esse parâmetro, pois as colunas *0* e *2* tem tipos misturados, e ao rodar usando esse parâmetro não retornou avisos.\n\nEm seguida, foi feito as etapas para criar o DataLoaders, começando por:\n\nFiz a leitura do arquivo *BX_Books.csv* para obter os nomes e números *ISBN* de cada um deles,","metadata":{}},{"cell_type":"code","source":"books = pd.read_csv(path/'Book reviews/Book reviews/BX_Books.csv', encoding='latin-1', delimiter=';', header=None, low_memory=False, usecols=(0,1), names=('isbn','title'))\nbooks = books.drop(0)\nbooks = books.reset_index(drop=True)\nbooks.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:35.432813Z","iopub.execute_input":"2023-07-04T00:02:35.433590Z","iopub.status.idle":"2023-07-04T00:02:37.631874Z","shell.execute_reply.started":"2023-07-04T00:02:35.433545Z","shell.execute_reply":"2023-07-04T00:02:37.630241Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         isbn  \\\n0  0195153448   \n1  0002005018   \n2  0060973129   \n3  0374157065   \n4  0393045218   \n\n                                                                                                title  \n0                                                                                 Classical Mythology  \n1                                                                                        Clara Callan  \n2                                                                                Decision in Normandy  \n3  Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It  \n4                                                                              The Mummies of Urumchi  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0195153448</td>\n      <td>Classical Mythology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002005018</td>\n      <td>Clara Callan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0060973129</td>\n      <td>Decision in Normandy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0374157065</td>\n      <td>Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0393045218</td>\n      <td>The Mummies of Urumchi</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Assim como anteriormente, tratei os dados contidos em `BX_Books.csv` com tratei para criar a variável `ratings`. \n\nComo instruido na aula do Jeremy, juntei a tabela `ratings` com a tabela `books`: ","metadata":{}},{"cell_type":"code","source":"ratings = ratings.merge(books)\nratings['rating'] = ratings['rating'].astype('int')\nratings.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:37.636733Z","iopub.execute_input":"2023-07-04T00:02:37.637169Z","iopub.status.idle":"2023-07-04T00:02:38.799299Z","shell.execute_reply.started":"2023-07-04T00:02:37.637117Z","shell.execute_reply":"2023-07-04T00:02:38.797688Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  user_id        isbn  rating                 title\n0  276725  034545104X       0  Flesh Tones: A Novel\n1    2313  034545104X       5  Flesh Tones: A Novel\n2    6543  034545104X       0  Flesh Tones: A Novel\n3    8680  034545104X       5  Flesh Tones: A Novel\n4   10314  034545104X       9  Flesh Tones: A Novel","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>rating</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>Flesh Tones: A Novel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2313</td>\n      <td>034545104X</td>\n      <td>5</td>\n      <td>Flesh Tones: A Novel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6543</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>Flesh Tones: A Novel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8680</td>\n      <td>034545104X</td>\n      <td>5</td>\n      <td>Flesh Tones: A Novel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10314</td>\n      <td>034545104X</td>\n      <td>9</td>\n      <td>Flesh Tones: A Novel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Agora, criei um objeto `DataLoaders` dessa tabela. Por padrão,as colunas *user_id*, *isbn* e *rating* serão utilizadas para produzir o objeto. Assim, mudei o valor de `item_name` no nosso caso para usar os títulos em vez dos IDs:","metadata":{}},{"cell_type":"code","source":"dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=824288)\ndls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:38.800853Z","iopub.execute_input":"2023-07-04T00:02:38.801264Z","iopub.status.idle":"2023-07-04T00:02:44.986367Z","shell.execute_reply.started":"2023-07-04T00:02:38.801219Z","shell.execute_reply":"2023-07-04T00:02:44.985240Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>title</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>143253</td>\n      <td>The Cunning Man: A Novel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>115490</td>\n      <td>Briar Rose</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>76352</td>\n      <td>Lake News</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17190</td>\n      <td>Left Behind Graphic Novel (Book 1, Vol.3 )</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>275970</td>\n      <td>The New Russians: Updated to Include the Failed Coup</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3363</td>\n      <td>Step-Ball-Change</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>242824</td>\n      <td>Charmed Circle (American Romance, No 301)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>269136</td>\n      <td>Penguin Readers Level 2: of Mice and Men (Penguin Readers)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>258907</td>\n      <td>The Metamorphosis, In the Penal Colony, and Other Stories</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>169357</td>\n      <td>Writ of Execution</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Descrevendo um pouco sobre o código, foi cirado o objeto `dls` que contém os dados necessários para treinar e validar o modelo de filtragem colaborativa. `CollabDataLoaders` é uma classe fornecida pelo fastai qua ajuda na criação dos `DataLoaders` que são responsáveis por fornecer os lotes de dados para o treinamento do modelo. O método estático `from_df` permite criar um objeto a partir de `ratings`. O parâmetro `item_name='title'` indica a coluna de `ratings` que contém os nomes dos itens, é necessário para que o modelo saiba como identificar cada item. O parâmetro `bs=824288` define o tamanho do lote usado durante o treinamento do modelo. O comando `dls.show_batch()` exibe uma amostra dos dados carregados nos `DataLoaders`.\n\nPara representar filtragem colaborativa em PyTorch não posso apenas usar a representação apresentada diretamente, especialmente quando quero encaixar o framework deep learning que vou usar. Representei as tabelas de fatores latentes de livros e usuários como matrizes simples:","metadata":{}},{"cell_type":"code","source":"n_users = len(dls.classes['user_id'])\nn_books = len(dls.classes['title'])\nn_factors = 50","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:44.990044Z","iopub.execute_input":"2023-07-04T00:02:44.990424Z","iopub.status.idle":"2023-07-04T00:02:44.996709Z","shell.execute_reply.started":"2023-07-04T00:02:44.990392Z","shell.execute_reply":"2023-07-04T00:02:44.995379Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"As variáveis `n_users` e `n_books` recebem o número de usuários e de livros no conjunto de dados. Isso pois foi utilizado a função `len()` para calcular o comprimento das colunas, selecionadas através de `dls.classes[coluna]`. Coloquei como *50* fatores latentes.\n\nAgora como parte da lição 7, o Jeremy passa pela criação do produto escalar por etapas. No caso, em referência à lição 7 fiz uma função de produto escalar:","metadata":{}},{"cell_type":"code","source":"class DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0, 10)):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.user_bias = Embedding(n_users, 1)\n        self.book_factors = Embedding(n_books, n_factors)\n        self.book_bias = Embedding(n_books, 1)\n        self.y_range = y_range\n    \n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        books = self.book_factors(x[:,1])\n        res = (users * books).sum(dim=1, keepdim=True)\n        res += self.user_bias(x[:,0]) + self.book_bias(x[:,1])\n        return sigmoid_range(res, *self.y_range)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:44.998819Z","iopub.execute_input":"2023-07-04T00:02:44.999958Z","iopub.status.idle":"2023-07-04T00:02:45.017559Z","shell.execute_reply.started":"2023-07-04T00:02:44.999917Z","shell.execute_reply":"2023-07-04T00:02:45.016303Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"No código acima tenho a importação da classe `Module` do módulo `torch.nn` do PyTorch que é usada para definir modelos de aprendizagem de máquina, dela é fronecido funcionalidades e métodos comuns para criar e gerenciar modelos. Assim, criei a classe `DotProductBias`, com `__init__` sendo construtor da classe que inicia os atributos da classe e define as camadas e parâmetros necessários para o modelo, `n_users` é o número de usuários e `n_books` de livros do conjunto dados, `n_factors` ~e o número de fatores latentes a serem usados, no caso definir como 5, `y_range` é um intervalo de valores esperados para as previsôes do modelo. Para as partes usando o `Embedding` estou fazendo uma incorporação para representar os usuários e os livros, no caso de `*_factors` estou querendo usar a camada de incorporação para representar os usuários e livros, no caso de `*_bias`estou querendo representar o viés dos usuários e livros. Seguindo para `foward()` este metodo define a passagem direta do modelo, sendo *x* um tensor de entrada que contém os índices dos usuários e filme, `users` e `books` usam as camadas de incorporação para obter os fatores latentes correspodentes a cada um dele presente em `x[:,0]` e `x[:,1]`. Assim faço a some do produto escalar dos fatores latentes de `users` e `books` em `(users * books).sum(dim=1, keepdim=True)` ao longo da dimensão 1 `dim=1` e matenho as dimensões da matriz em `keepdim=True`. O resultado dessa soma é uma matriz de previsões parciais para cada par usuário-livro. Assim sigo para adicionar os viéses dos usuário e dos filme às previsões parcias, auxiliando as previsões de acordo com os padrões específicos de cada usuário e livro em `res += self.user_bias(x[:,0]) + self.book_bias(x[:,1])`. Com isso feito, dou um retorno da função `sigmoid_range` em que é aplicado uma função de ativação sigmoidal às previsões resultantes e aplica um redimensionamento linear para garantir que as previsões estejam dentro do intervalo definidao por `y_range`.\n\nAgora treino o modelo aplicando o conceito de Decaimento por peso, que consiste em adicionar para a função de loss a soma de todos os pasos ao quadrado, para encorajar o pesos a serem o mais pequenos possíveis:","metadata":{}},{"cell_type":"code","source":"model = DotProductBias(n_users, n_books, n_factors)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(20, 10e-2, wd=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:02:45.019663Z","iopub.execute_input":"2023-07-04T00:02:45.020535Z","iopub.status.idle":"2023-07-04T00:04:15.257775Z","shell.execute_reply.started":"2023-07-04T00:02:45.020490Z","shell.execute_reply":"2023-07-04T00:04:15.256794Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>19.532913</td>\n      <td>19.462479</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>19.481537</td>\n      <td>19.226902</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>19.361034</td>\n      <td>18.683155</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>19.117989</td>\n      <td>17.847898</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>18.735947</td>\n      <td>16.765671</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>18.199915</td>\n      <td>15.483126</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>17.493793</td>\n      <td>14.224391</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>16.642176</td>\n      <td>13.353561</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>15.720423</td>\n      <td>12.937882</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>14.798668</td>\n      <td>12.795275</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>13.910779</td>\n      <td>12.792434</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>13.069999</td>\n      <td>12.870206</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>12.283953</td>\n      <td>12.995020</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>11.557717</td>\n      <td>13.135524</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>10.893091</td>\n      <td>13.266660</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>10.288601</td>\n      <td>13.372946</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>9.740789</td>\n      <td>13.447824</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>9.245260</td>\n      <td>13.492058</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>8.797400</td>\n      <td>13.511828</td>\n      <td>00:04</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>8.392585</td>\n      <td>13.516588</td>\n      <td>00:04</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"No código acima, criei uma instância do modelo `DotPRoductBias` com base no número de usuários, número de livros e 50 fatores latentes. Em seguida, ele cria um objeto `Learner` com base nos dados de treinamento, no modelo e a função de perda `MSELossFlat`. Depois disso apliquei o método `fit_one_cycle` para treinar o modelo por 5 épocas, com uma taxa de aprendizagem inicial de ... e uma peso de decaimento (weight decay) de 0.1.\n\nAgora para finalizar a parte do desenvolvimento do artigo e da produção do modelo, criei um modelo deep learning para a filtragem colaborativa. Para isso, comecei colocando na variável `embs` o retorno da recomendação da função do *fastai* `get_emb_sz` dá de tamanho de incorporação de matrizes para o dado que estou usando,","metadata":{}},{"cell_type":"code","source":"embs = get_emb_sz(dls)\nembs","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:04:15.259189Z","iopub.execute_input":"2023-07-04T00:04:15.260102Z","iopub.status.idle":"2023-07-04T00:04:15.267074Z","shell.execute_reply.started":"2023-07-04T00:04:15.260061Z","shell.execute_reply":"2023-07-04T00:04:15.266154Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[(92108, 600), (241091, 600)]"},"metadata":{}}]},{"cell_type":"markdown","source":"Agora implemento essa classe:","metadata":{}},{"cell_type":"code","source":"class CollabNN(Module):\n    def __init__(self, user_sz, item_sz, y_range=(0,11), n_act=100):\n        self.user_factors = Embedding(*user_sz)\n        self.item_factors = Embedding(*item_sz)\n        self.layers = nn.Sequential(\n            nn.Linear(user_sz[1]+item_sz[1], n_act),\n            nn.ReLU(),\n            nn.Linear(n_act, 1))\n        self.y_range = y_range\n        \n    def forward(self, x):\n        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n        x = self.layers(torch.cat(embs, dim=1))\n        return sigmoid_range(x, *self.y_range)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:04:15.268436Z","iopub.execute_input":"2023-07-04T00:04:15.269532Z","iopub.status.idle":"2023-07-04T00:04:15.281938Z","shell.execute_reply.started":"2023-07-04T00:04:15.269472Z","shell.execute_reply":"2023-07-04T00:04:15.280540Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"A classe `CollabNN` implementa um modelo de filtragem colaborativa com redes neurais. Esse modelo é usado para fazer previsões ou recomendações com base em dados de usuários e itens, analisando como ele funciona tenho:\n\nNo método `__init__`, são definidos os atributos da classe. `user_sz` e `item_sz` são tuplas que contêm o número de usuários e itens no conjunto de dados, respectivamente, bem como a dimensão dos fatores latentes para usuários e itens. O intervalo `y_range` especifica os valores esperados das previsões do modelo, e `n_act` determina o número de neurônios na camada oculta da rede neural.\n\nEm seguida, são criadas as camadas de incorporação (embedding) para representar os usuários e itens. A camada de incorporação para os usuários tem dimensão de acordo com `user_sz`, e a camada de incorporação para os itens tem dimensão de acordo com `item_sz`.\n\nA rede neural é definida usando a classe `nn.Sequential`, que permite empilhar camadas sequencialmente. Ela consiste em uma camada linear de entrada, uma função de ativação `ReLU` e uma camada linear de saída. A camada linear de entrada recebe as representações concatenadas dos usuários e itens como entrada, enquanto a camada linear de saída produz uma única saída, que é a previsão final do modelo.\n\nNo método `forward`, o tensor de entrada *x* contém os índices dos usuários e itens. A partir desses índices, são obtidas as representações de incorporação dos usuários e itens correspondentes. Essas representações são então concatenadas ao longo da dimensão 1 para formar um único tensor de entrada para a rede neural.\n\nEsse tensor é passado pelas camadas da rede neural definidas anteriormente, e a saída resultante é aplicada a uma função de ativação sigmoidal. Essa função sigmoidal garante que as previsões estejam dentro do intervalo especificado por `y_range`. Por fim, as previsões redimensionadas são retornadas como saída do método forward.\n\nE assim, utilizo para criar o modelo e fazer o treino dele:","metadata":{}},{"cell_type":"code","source":"model = CollabNN(*embs)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(15, 10e-2, wd=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T00:04:15.284052Z","iopub.execute_input":"2023-07-04T00:04:15.284552Z","iopub.status.idle":"2023-07-04T00:14:56.344282Z","shell.execute_reply.started":"2023-07-04T00:04:15.284507Z","shell.execute_reply":"2023-07-04T00:14:56.342757Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>20.607233</td>\n      <td>20.228888</td>\n      <td>00:33</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>20.407421</td>\n      <td>15.414684</td>\n      <td>00:29</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>18.643677</td>\n      <td>16.505472</td>\n      <td>00:29</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>17.803856</td>\n      <td>19.885031</td>\n      <td>00:30</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>17.729347</td>\n      <td>16.281061</td>\n      <td>00:29</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>17.269590</td>\n      <td>16.207882</td>\n      <td>01:16</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>16.665724</td>\n      <td>16.746372</td>\n      <td>00:54</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>16.454834</td>\n      <td>15.700248</td>\n      <td>00:51</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>16.031324</td>\n      <td>15.990754</td>\n      <td>00:48</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>15.666648</td>\n      <td>15.449700</td>\n      <td>00:44</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>15.306998</td>\n      <td>15.445907</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>15.009542</td>\n      <td>15.434989</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>14.741873</td>\n      <td>15.436027</td>\n      <td>00:41</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>14.502277</td>\n      <td>15.446247</td>\n      <td>00:41</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>14.291379</td>\n      <td>15.448464</td>\n      <td>00:38</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Essas linhas de código têm o objetivo de criar e treinar um modelo de filtragem colaborativa. Entendendo o que cada parte faz:\n\nNa linha `model = CollabNN(*embs)`, um objeto chamado model é criado. Ele representa o modelo de filtragem colaborativa e utiliza as representações de incorporação dos usuários e itens, que estão armazenadas na variável embs. O desempacotamento `(*embs)` permite passar as representações corretas para o construtor da classe *CollabNN*, inicializando o modelo adequadamente.\n\nNa linha `learn = Learner(dls, model, loss_func=MSELossFlat())`, um objeto chamado learn é criado. Ele representa o objeto de aprendizado (learner) responsável por treinar o modelo. O objeto dls contém o conjunto de dados de treinamento e validação. O modelo criado anteriormente (model) é passado como argumento, juntamente com a função de perda *MSELossFlat()*, que mede o erro quadrático médio entre as previsões do modelo e os rótulos reais.\n\nNa linha `learn.fit_one_cycle(15, 10e-2, wd=0.01)`, o método `fit_one_cycle()` é chamado para treinar o modelo. Ele recebe três argumentos: o número de épocas de treinamento (15), a taxa de aprendizado (10e-2) e a força da regularização (0.01). Durante o treinamento, o modelo será ajustado aos dados em várias iterações (épocas) para fazer previsões mais precisas.\n\nFeito isso, passei para a exportação do modelo para utilizá-lo no aplicativo do Hugging Face:","metadata":{}},{"cell_type":"code","source":"learn.export('model.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T01:43:31.118251Z","iopub.execute_input":"2023-07-04T01:43:31.119569Z","iopub.status.idle":"2023-07-04T01:43:35.842832Z","shell.execute_reply.started":"2023-07-04T01:43:31.119517Z","shell.execute_reply":"2023-07-04T01:43:35.841201Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Conclusão\n\nAchei interessante construir um modelo de recomendação utilizando filtros colaborativos e também presenciei bastantes dificuldades com o dataset, tive problemas de linguagem *encoding*, a coluna de ratings estava vindo como objetos e o *DataLoader* só trabalhos com valores númericos, na hora de usar o modelo em produto escalar teve um momento em que fique 1 hora esperando o fazer o primeiro ciclo de treinamento, no HuggingFace App na hora de pedir para fazer a sugestão está dando error. Então finalizando, foi trabalhoso e divertido estudar sobre filtros colaborativos e gradientes descedentes.\n","metadata":{}}]}